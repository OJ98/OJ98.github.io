---
layout: archive
title: ""
permalink: /experiences/
author_profile: true
---

Professional Experience 
======
### *Full Stack Developer*, Equities Tech, Credit Suisse Services AG, Pune [July 2021 - July 2022]
- Designed, developed and deployed a new service to integrate Stock Borrow Agreement data into existing database architecture post new financial legislation being passed in Hong Kong in 2021.
- Developed a modern UI for an internal tool to replace EquiLend NGT.
- Migrated 200+ active, interdependent jobs to new servers using Control-M.

### *Front End Developer*, International Wealth Management, Credit Suisse Services AG, Pune [July 2020 - July 2021]
- Migrated internal dashboards from AngularJS to Angular6.

### *Intern*, International Wealth Management, Credit Suisse Services AG, Pune [May 2019 - July 2019]

---

Projects and Code
======
### A Basic Game Engine [link](https://github.com/OJ98/Game_Engine_Design_Final_Project/tree/main)
<div style="width: 80%;">
    This is an implementation of a basic game engine in C++. The engine was developed for a basic platformer and achieves code reuse of ~95% for an implementation of Flappy Bird and ~82% for an implementation of Space Invaders.
</div>

### JChat - A JATMO-inspired Universal LLM chat Prompt Injection Defender [link](https://github.com/davidroot8/JChat)
<div style="width: 80%;">
    Large Language Models (LLMs) are one of the most significant innovations of the past decade due to their immense scope and versatility. However, it is this same scope that makes LLMs vulnerable to prompt-based attacks including prompt injection. To the best of our knowledge, there is no comprehensive defense technique against prompt injection. Most popular models including Meta AI’s LLaMa series and OpenAI’s GPT series are vulnerable to prompt injection. This paper proposes a detection-elimination based approach to the problem of prompt injection defense. We evaluate this approach on three parameters - effectiveness, performance and efficiency and report comparative results against baselines including GPT3.5 and LlaMa2.
</div>

### Argumentation-based Link Prediction using LLMs \[[link](https://github.com/OJ98/Argumentation-based-Link-Prediction-using-LLMs)\]
<div style="width: 80%;">    
    The problem of link prediction aims to forecast future connections between users based on the existing network structure and user data. Accurate predictions can enhance content discovery, increase user engagement, and optimize information flow across the network. By suggesting relevant accounts to follow, link prediction accelerates network growth and potentially bridges disparate communities, thereby reducing echo chambers. It also plays a crucial role in improving targeted marketing, content recommendations, and the overall relevance of user feeds. Successful link prediction can lead to a more connected, engaging, and valuable social media experience for users while offering strategic benefits for the platform. Applying an argumentation-based approach to this problem can help us extract more relevant information from a smaller amount of data due to the nature of argumentation revealing more useful information about a user’s personality. Due to charged nature of arguments on platforms such as Twitter, we think we can perform the task of link prediction more effectively with a small sample size as more traits of the user are likely to be revealed. This can be validated by simply checking the accuracy of the system’s prediction and comparing to a suitable baseline. A charged argument in this case would be one where there is a back and forth interaction between two or more users on a topic on which strong opinions are held, whether political, social or cultural. The main hypothesis of the project is : an argumentation-based approach to the task of link prediction can outperform traditional baselines on certain metrics.
</div>

### Phishing and LLMs
<div style="width: 80%;">
</div>